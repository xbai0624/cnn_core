Debug: Layer:1 init neruons done.
Debug: Layer:1 TransferValueFromOriginalToActiveWB() done.
----------- Layer ID: 1 ------------
layer type: FC
drop out factor: 0.5
use drop out: 1
number of fc neurons: 20
number of cnn kernels: 0
kernel  dimension:      0     0

 --- w&b 
weight matrix : 0
   0.0340756    0.248881   0.0392923   -0.118784    0.242866    0.732688  -0.0290482    0.226472   -0.343446 -0.00417288
   -0.195669   -0.302087   -0.322457    0.269664    0.215477   -0.140023  -0.0309627   0.0577661  -0.0828029   -0.347228
    0.142555    0.244666   -0.265031   0.0254701   -0.227714    0.237205   0.0445362  -0.0254421   -0.229878    0.164094
   -0.171457   -0.106196   -0.462736   0.0559257   -0.132328   -0.247945    0.206388   0.0520752    0.175773    -0.40452
    0.177166    0.216283   -0.393003  -0.0947828  -0.0249157    0.110974  -0.0412197    0.115258    0.318125   -0.137099
    0.137568    0.206771   -0.252795   0.0714468    -0.14461   -0.035819   0.0285661   -0.329991   -0.307143    0.164874
  -0.0704363 -0.00953162  -0.0842568  0.00577182   -0.159033  -0.0136492   -0.177679   -0.306898  -0.0941726    0.136387
    0.260116   -0.087838  -0.0471488   0.0419171   0.0243989   -0.256403   -0.174152    0.183559   -0.112575    0.283104
   0.0782468  -0.0329665   -0.173498  -0.0779444  -0.0769368   0.0341495   0.0287022   -0.328405  -0.0331642   -0.183261
   -0.181143   -0.227011  -0.0567964   -0.389445   0.0501596   -0.120137  -0.0866708    0.133301   -0.305437    0.222671
    -0.35309   0.0530726   -0.336852   -0.312247   0.0382614   -0.105662  -0.0436058   -0.120812   -0.404746     0.43414
   -0.225329  -0.0192537   -0.166717   -0.126121    0.405931   0.0649972   -0.038661    0.395608  -0.0297244   -0.106777
   0.0576842    0.162191  -0.0987532  -0.0216227  -0.0704684  -0.0728208    0.204063    0.215165   0.0758216   0.0182799
    0.351762    0.382251 -0.00136299  -0.0633804   -0.222943   -0.195263     0.11678    0.550692   -0.213532   -0.184382
   0.0258043    0.256829  -0.0624143   -0.117718  -0.0660388    0.139299    0.180011    0.203573    0.288682  -0.0226426
   0.0405521   -0.209037   -0.229477   -0.180048   -0.194795    0.181038  -0.0224666    0.389752   -0.014983   0.0132997
    0.224545  0.00113378    0.114528  -0.0962632    -0.23427    0.344258    0.191658  -0.0622178   -0.468333   0.0557119
  -0.0937823   -0.321577   0.0156019    0.176602  -0.0586618   -0.304696   -0.287278   -0.269404   -0.196874    0.156073
    -0.48357    0.504928    0.233521  -0.0227307   0.0439422   -0.133569     0.20394    0.062288    0.153443    0.189375
    0.095701     0.32469   -0.318747    0.193165    0.113183   -0.423645    0.214072   -0.323432    0.346315  -0.0645447

bias matrix: 0
   -0.328676
   0.0218834
   -0.252733
   -0.238881
   0.0252906
   -0.165872
   -0.894859
  -0.0989736
    0.881435
     1.44423
     1.04937
     1.35082
     1.37819
     1.17683
     1.17706
     2.02126
   -0.677255
      1.2471
   -0.317514
    -1.60439

 --- active flag matrix 
active flag : 0
   1
   0
   1
   0
   0
   0
   1
   1
   1
   1
   0
   1
   0
   0
   0
   0
   1
   1
   0
   1

 --- active w&b 
active weight matrix : 0
   0.0340756    0.248881   0.0392923   -0.118784    0.242866    0.732688  -0.0290482    0.226472   -0.343446 -0.00417288

active bias matrix: 0
   -0.328676

active weight matrix : 1
    0.142555    0.244666   -0.265031   0.0254701   -0.227714    0.237205   0.0445362  -0.0254421   -0.229878    0.164094

active bias matrix: 1
   -0.252733

active weight matrix : 2
  -0.0704363 -0.00953162  -0.0842568  0.00577182   -0.159033  -0.0136492   -0.177679   -0.306898  -0.0941726    0.136387

active bias matrix: 2
   -0.894859

active weight matrix : 3
    0.260116   -0.087838  -0.0471488   0.0419171   0.0243989   -0.256403   -0.174152    0.183559   -0.112575    0.283104

active bias matrix: 3
  -0.0989736

active weight matrix : 4
   0.0782468  -0.0329665   -0.173498  -0.0779444  -0.0769368   0.0341495   0.0287022   -0.328405  -0.0331642   -0.183261

active bias matrix: 4
    0.881435

active weight matrix : 5
   -0.181143   -0.227011  -0.0567964   -0.389445   0.0501596   -0.120137  -0.0866708    0.133301   -0.305437    0.222671

active bias matrix: 5
     1.44423

active weight matrix : 6
   -0.225329  -0.0192537   -0.166717   -0.126121    0.405931   0.0649972   -0.038661    0.395608  -0.0297244   -0.106777

active bias matrix: 6
     1.35082

active weight matrix : 7
    0.224545  0.00113378    0.114528  -0.0962632    -0.23427    0.344258    0.191658  -0.0622178   -0.468333   0.0557119

active bias matrix: 7
   -0.677255

active weight matrix : 8
  -0.0937823   -0.321577   0.0156019    0.176602  -0.0586618   -0.304696   -0.287278   -0.269404   -0.196874    0.156073

active bias matrix: 8
      1.2471

active weight matrix : 9
    0.095701     0.32469   -0.318747    0.193165    0.113183   -0.423645    0.214072   -0.323432    0.346315  -0.0645447

active bias matrix: 9
    -1.60439

Debug: Layer:2 init neruons done.
Debug: Layer:2 TransferValueFromOriginalToActiveWB() done.
----------- Layer ID: 2 ------------
layer type: FC
drop out factor: 0.5
use drop out: 1
number of fc neurons: 10
number of cnn kernels: 0
kernel  dimension:      0     0

 --- w&b 
weight matrix : 0
   -0.244507   0.0218322   0.0181348 -0.00134691    0.549019    -0.15437   -0.276954   0.0725329     0.72543   -0.157997    -0.26786   -0.110722     0.67333   -0.264308   -0.415596    0.473573    0.147147   -0.289864   -0.531436   0.0697006
   -0.315314    0.159867   -0.105342  0.00748599   -0.409673   0.0365226    0.782777    -0.53394    0.258572    -0.23737  -0.0626539   -0.039519    0.522262    0.375317   -0.854119    0.558254   -0.323915    0.168789    0.595222   -0.174632
   -0.163227   0.0506518  -0.0333763   -0.241434  0.00372089   -0.179301  -0.0632472   -0.125881   -0.121617    0.070475    0.254568    0.269137   -0.287768   -0.246667   -0.276597   -0.119892  -0.0816294    0.132138   -0.560911   -0.057434
    0.329095   0.0158171   -0.403245   -0.115232   -0.189552   -0.916788   -0.171164    0.110007    0.546072    0.582948   -0.419496  -0.0414308  -0.0206491    0.172139    0.206676    0.226727    0.386314  -0.0362991    0.320931    0.451653
   -0.350385   -0.457037   -0.030733   -0.257345   -0.140092     0.22516  -0.0267368    0.154071   -0.180669 -0.00469857   -0.576467   0.0383854    0.093233   -0.212077    0.147054    0.526133    0.281327    0.538456   -0.269408   -0.334227
   -0.549817    0.446736  -0.0428176    -0.18807    -0.24784    0.169951   -0.544876    0.194586    0.275747    0.212204   0.0232167    0.213859    0.118494     0.56537    0.237922    0.578612    0.595781    0.134351  -0.0507654    0.526751
   -0.355154      0.1606     0.45966    0.165585   -0.342161    -0.28175    0.157292   0.0226086  -0.0328739    0.253672   0.0354067   -0.247554    0.192954  -0.0273759    0.099675    0.396909   -0.120182    0.349914    0.178414   0.0869713
    0.177088    0.126312   -0.202369    0.271974   -0.326488    0.353987    0.214795    0.339822   -0.487888  0.00917172     0.16927     0.12119   -0.251727   -0.266685   0.0233636    0.356023    0.373419    0.238987    0.185495    -0.43781
   -0.418197   0.0413829    0.229144   -0.586034  -0.0734836   -0.184294  -0.0176257    0.379725   -0.975768   -0.219926    0.262852   -0.641086   -0.030369    0.387852    0.644336    0.221904     0.89514    0.189555    -0.13981   -0.059516
    0.461662   -0.129633     0.55642    0.635968   -0.113901   -0.175015    0.143525    0.140827   -0.167193    0.148052   -0.148686    0.327505    0.391863    0.110812    0.169219    0.278433  -0.0392699   0.0956472    0.425309   -0.166919

bias matrix: 0
   -0.113114
    0.198711
    0.225476
    -1.02783
    0.282741
     1.09135
    0.599418
     1.84696
    0.349339
   -0.216506

 --- active flag matrix 
active flag : 0
   1
   0
   0
   0
   1
   0
   1
   0
   1
   1

 --- active w&b 
active weight matrix : 0
   -0.244507   0.0181348   -0.276954   0.0725329     0.72543   -0.157997   -0.110722    0.147147   -0.289864   0.0697006

active bias matrix: 0
   -0.113114

active weight matrix : 1
   -0.350385   -0.030733  -0.0267368    0.154071   -0.180669 -0.00469857   0.0383854    0.281327    0.538456   -0.334227

active bias matrix: 1
    0.282741

active weight matrix : 2
   -0.355154     0.45966    0.157292   0.0226086  -0.0328739    0.253672   -0.247554   -0.120182    0.349914   0.0869713

active bias matrix: 2
    0.599418

active weight matrix : 3
   -0.418197    0.229144  -0.0176257    0.379725   -0.975768   -0.219926   -0.641086     0.89514    0.189555   -0.059516

active bias matrix: 3
    0.349339

active weight matrix : 4
    0.461662     0.55642    0.143525    0.140827   -0.167193    0.148052    0.327505  -0.0392699   0.0956472   -0.166919

active bias matrix: 4
   -0.216506

Debug: Layer:3 init neruons done.
Debug: Layer:3 TransferValueFromOriginalToActiveWB() done.
----------- Layer ID: 3 ------------
layer type: cnn
drop out factor: 0.5
use drop out: 1
number of fc neurons: 0
number of cnn kernels: 5
kernel  dimension:      6     6

 --- w&b 
weight matrix : 0
    -0.13089    0.125069     -0.1253   -0.540375    0.025987   -0.485344
    0.764367    0.249805    0.119421  -0.0945711  -0.0125696   -0.350214
   -0.675072    0.033436    0.246299   -0.568029   -0.204925    0.458425
    0.314546   -0.190747   -0.551546    -1.05153   -0.856803   -0.355721
    0.294382    0.199163  -0.0249719   0.0730553    0.112846    0.394121
    -0.05077    0.535941     -0.4859    0.357239    0.954683   -0.176841

bias matrix: 0
   -0.962996

weight matrix : 1
   -0.404652   -0.215351   -0.412278   -0.172795   -0.165526    0.718825
  -0.0966233   -0.149215    0.137302    0.351256  -0.0801957    0.764584
    0.339611    -0.29029 -0.00859843  0.00468726  -0.0648623    0.285724
   -0.236138    -0.48594   -0.064644   -0.124696    0.427074   0.0819925
    0.347572      0.0505   -0.647603    0.506489   -0.432132   -0.172045
    0.355503    -0.31732     0.40041   -0.850845    -0.25008    0.337673

bias matrix: 1
     1.06398

weight matrix : 2
   -0.412667   -0.180773   -0.549237    0.133975   -0.221791    0.168743
   -0.479822    0.671638    0.164416   0.0885663    0.268134   -0.376484
    0.532772    -0.10108    0.132407   -0.207157   -0.197729   -0.163653
   -0.604299   -0.295547     0.13359       0.437   -0.347658   -0.207205
   -0.348044   -0.219093   0.0719912   -0.129209    0.642222  -0.0254562
    0.354808   -0.340794   -0.253402   -0.503265  -0.0602063     0.63226

bias matrix: 2
    0.232716

weight matrix : 3
 -0.00946928     0.31992    0.767798  -0.0670831   0.0326996    0.567892
     0.35793   -0.269669  -0.0853867    0.205606   0.0360083   -0.522942
     0.09954    0.197449   -0.530775    0.401858    0.251441    0.359164
   -0.407943   -0.883533  -0.0888411    -0.70091   -0.185097   -0.110252
   0.0787608   -0.155169   -0.333772    0.649342   -0.283061   -0.177892
   -0.260602  -0.0613134   -0.907802   -0.117439  -0.0923156   -0.103055

bias matrix: 3
     1.22058

weight matrix : 4
   -0.172301    0.500838   -0.572499   -0.109722  -0.0387098    0.200409
    0.258112   -0.342201   -0.442836    0.119951   -0.393765   -0.266376
    0.417863   -0.869886  -0.0111974    0.229272   -0.131132    0.605018
    0.201204    0.103391   -0.288793    0.509167   -0.298895   -0.291469
   -0.114545   -0.495735    0.185179    0.446087   -0.692441    0.284779
   0.0605691   0.0352136   0.0221757   -0.313295   -0.185007    0.138284

bias matrix: 4
     1.93379

 --- active flag matrix 
active flag : 0
   1   1   1   1   1   1
   0   1   0   0   1   1
   0   1   1   1   0   0
   0   1   0   1   1   0
   1   0   0   0   0   0
   1   1   0   0   0   0

active flag : 1
   0   0   1   0   1   0
   1   1   1   0   0   0
   1   1   0   0   1   1
   1   0   1   1   0   0
   1   0   1   1   1   0
   0   0   0   0   1   1

active flag : 2
   0   1   1   0   0   0
   1   1   1   1   1   0
   1   0   0   1   0   0
   1   0   1   0   0   0
   1   1   0   0   1   1
   1   1   0   1   0   0

active flag : 3
   1   1   1   1   0   0
   1   0   1   1   1   0
   1   0   0   1   1   0
   1   0   0   1   0   0
   1   0   0   0   1   1
   1   0   0   0   1   0

active flag : 4
   0   1   0   0   1   1
   1   0   0   1   0   0
   1   1   0   0   1   0
   0   1   1   0   1   1
   0   0   0   1   1   1
   1   0   1   0   1   0

 --- active w&b 
active weight matrix : 0
    -0.13089    0.125069     -0.1253   -0.540375    0.025987   -0.485344
           0    0.249805           0           0  -0.0125696   -0.350214
           0    0.033436    0.246299   -0.568029           0           0
           0   -0.190747           0    -1.05153   -0.856803           0
    0.294382           0           0           0           0           0
    -0.05077    0.535941           0           0           0           0

active bias matrix: 0
   -0.962996

active weight matrix : 1
           0           0   -0.412278           0   -0.165526           0
  -0.0966233   -0.149215    0.137302           0           0           0
    0.339611    -0.29029           0           0  -0.0648623    0.285724
   -0.236138           0   -0.064644   -0.124696           0           0
    0.347572           0   -0.647603    0.506489   -0.432132           0
           0           0           0           0    -0.25008    0.337673

active bias matrix: 1
     1.06398

active weight matrix : 2
           0   -0.180773   -0.549237           0           0           0
   -0.479822    0.671638    0.164416   0.0885663    0.268134           0
    0.532772           0           0   -0.207157           0           0
   -0.604299           0     0.13359           0           0           0
   -0.348044   -0.219093           0           0    0.642222  -0.0254562
    0.354808   -0.340794           0   -0.503265           0           0

active bias matrix: 2
    0.232716

active weight matrix : 3
 -0.00946928     0.31992    0.767798  -0.0670831           0           0
     0.35793           0  -0.0853867    0.205606   0.0360083           0
     0.09954           0           0    0.401858    0.251441           0
   -0.407943           0           0    -0.70091           0           0
   0.0787608           0           0           0   -0.283061   -0.177892
   -0.260602           0           0           0  -0.0923156           0

active bias matrix: 3
     1.22058

active weight matrix : 4
           0    0.500838           0           0  -0.0387098    0.200409
    0.258112           0           0    0.119951           0           0
    0.417863   -0.869886           0           0   -0.131132           0
           0    0.103391   -0.288793           0   -0.298895   -0.291469
           0           0           0    0.446087   -0.692441    0.284779
   0.0605691           0   0.0221757           0   -0.185007           0

active bias matrix: 4
     1.93379

